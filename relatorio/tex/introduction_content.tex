\chapter{Introduction}

In recent years, the use and management of energy has become a global issue. The search is on for renewable energies that reduce the ecological impact on our planet. However, these alternatives are neither as cheap nor as consistent as traditional options. There are many areas in which that may reduce their energy footprint, and the IT sector is one of them.

Saving energy in programs is crucial for the operation of certain devices, such as mobile phones or IoT devices, so certain techniques need to be applied in order to reduce the energy of a program. For mobile devices, companies such as Google and Apple have developed tools\cite{google_adaptive_battery,google_battery_saver,apple_clean_energy, android_power_profiler} to help save energy and while running the applications techniques are already used to save the battery when necessary, but for systems that don't use batteries, such as servers, energy is rarely taken into account when developing a program. This lack of concern or awareness on the part of developers, although it appears to have a small impact, turns out to be quite significant; In 2020 around 7\% of global electricity use was due to information and communications technology, with an anticipated rise in line with the growing demand for new technologies\cite{article}. This trend has become even more significant with the increased use of artificial intelligence \cite{patterson2021carbon}, especially large scale models such as ChatGPT, which require significant computing resources to train and run. These energy-intensive processes contribute significantly to global energy consumption and carbon emissions, raising environmental concerns as AI adoption continues to grow. For instance, training the GPT-3 model required 1,287 MWh of energy, equivalent to the annual energy usage of approximately 117 U.S. households, and produced 552 metric tons of CO2—comparable to the emissions from driving 120 cars for a year. With the release of GPT-4 and ongoing development of even more advanced models, these numbers are expected to rise, further amplifying their environmental footprint. The significant energy demands of data centers lead to considerable heat generation, requiring Heating, Ventilation, and Air Conditioning (HVAC) systems to ensure stable operations. Remarkably, HVAC systems consume approximately 33\% of a data center's total energy, with another 18\% dedicated to Computer Room Air Conditioning (CRAC) units. Servers, which are integral to data center functionality, account for 45\% of the energy usage, even without factoring in AI-driven tasks and complex modeling workloads~\cite{balaras2017high}.

Some key reasons to prioritize energy efficiency in software, whether for mobile systems or data center applications, include:

\begin{itemize}
  \item The dependence of mobile devices on batteries. All mobile devices rely on their batteries, so the software they run needs to make the best use of resources to conserve battery power.
  \item Reducing operating costs in data centers. It is crucial to reduce the operating cost of data centers by using energy-efficient programs. This reduction results in economic benefits for companies and contributes positively to environmental sustainability. 
  \item Reducing energy consumption has a positive impact on our environment by saving energy that can be used more efficiently elsewhere. 
\end{itemize}

When developing a program, most of the time developers optimize for the time the program takes to complete, or the memory it uses, and not so often take into account the energy it uses. 
In the cases where developers actually want to improve the energy efficiency of the code, they normally have difficulties and seek help, relying on blogs, websites and YouTube videos, which in most cases lack empirical evidence, leading to perceptions of improvement rather than measured benefits\cite{10.1145/3154384}. This is due to a lack of knowledge and guidelines, because understanding the energy usage of a program and how to make it more efficient is not trivial, as running the same program multiple times will output different values each time and even if the execution time of the program is reduced, is not guaranteed to also reduce energy consumption. Because of its difficulty, there is still a need for tools that can help with this task\cite{10.1145/2597073.2597110}. 

Also, most current tools can measure the energy of programs and applications as they run (e.g., Android Studio Power Profiler~\cite{android_power_profiler}), but this usually requires extra steps that many developers may not have the time or inclination to take, so there is a need for a tool that can help the developer without the need for extra effort\cite{10.1145/3154384}.

This thesis proposes the development of a tool capable of identifying the energy consumption of methods in programs and presenting this information quickly to programmers, enabling them to make informed decisions in software design. The goal is to create an IDE extension that integrates these functionalities, provides immediate feedback on the energy impact of applications, and allows developers to adjust their code to meet efficiency requirements. The tool should be easy to use, requiring minimal knowledge of energy consumption, while helping programmers understand the energy footprint of their software. This increased awareness will enable them to understand the overall impact of their coding choices on energy consumption and efficiency.

To create this tool, it is essential to understand the current state of the art, including the techniques previously used and the tools currently in use. The tool will employ static analysis techniques to identify which instructions are utilized, and through inferences from previously collected data, indicate the estimated energy levels of the program's execution. The inference will be made using energy data collected from low-level library functions. More complex functions are built on the basis of function composition, which means that, based on the estimated consumption of low-level functions, we can generalize our estimates to more complex functions and ultimately to the program as a whole. 

\section{Motivation}



\section{Objectives}

\blindtext[1]

\blindtext[2]

\section{Contributions}

\Blindtext[2]

\section{Document Structure}

This document is organized as follows:

\begin{itemize}
\item Chapter \ref{chapter:background} – introduces key concepts necessary to fully understand the report. It discusses the challenges of predicting and measuring energy consumption in programs, explores various energy tools and machine learning techniques, and provides an overview of static and dynamic analysis, highlighting their relevance to this work.

\item Chapter \ref{chapter:related_work} – contains the initials solutions proposed to the theme of energy aware programming, how they changed during the years, and what the most recent tools do. And comparing with the proposed tool in this work.

\item Chapter \ref{chapter:methodology} - explains in detail the existing problem and what is the solution, and a detailed explanation on how the solution will be built.

\item Chapter \ref{chapter:results} - reports on the experiments made so far, and the obtained results.

\item Chapter \ref{chapter:conclusion} - summarizes the work completed to date.

\item Chapter \ref{chapter:future_work} - outlines future research directions.

\end{itemize}