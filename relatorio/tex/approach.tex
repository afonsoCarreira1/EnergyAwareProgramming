\chapter{Approach}\label{chapter:approach} \textcolor{blue}{Tudo novo}


As described in the previous sections, the aim of this work is to make developers aware of the energy consumption of their programs. By using a simple and practical tool, they can quickly and accurately estimate their program's energy consumption. This allows them to get immediate feedback on energy consumption with every code change, facilitating energy-efficient development. It is important to note that this tool serves as a guide, providing energy consumption estimates to raise awareness rather than dictate action. Ultimately, it is up to developers to decide whether to prioritize performance, energy efficiency or any other factor. For example, if a program only needs to run within a certain timeframe and can afford a slight reduction in performance, developers may choose to trade some performance for improved energy efficiency, making more informed decisions thanks to the insights provided by the tool.

To provide this insight to developers it is necessary to build a tool that can provide all of that. The tool needs to be practical, which means that integrating it in an IDE is recommended. With this the developer only needs to download an extension for an IDE and will access to the insights provided by the tool.


The tool will be a VSCode extension built using the Language Server Protocol (LSP). While VSCode may not be the most commonly used IDE for Java projects compared to Eclipse or IntelliJ IDEA, it provides a much simpler and more accessible environment for developing and testing extensions. This will make it accessible to most developers wanting feedback on the energy consumption. To make it fast, it will use static analysis to parse the code into an AST, from there it is capable of analyzing the code and using an inference function it will output the estimated cost.
Although the tool is initially built for VSCode, its use of the LSP standard means it can be extended to other IDEs like Eclipse or IntelliJ IDEA. Since LSP handles the communication between the language server and the development environment, porting the tool to new IDEs would primarily involve adapting the user interface and integration specifics, rather than reworking the core logic.


Many devices rely on Java and the JVM, so it is important that the code they run is energy efficient. Several factors can affect the power consumption of Java applications, including the behavior of the garbage collector and the efficiency of the memory management system ~\cite{10.5555/1267847.1267870} making it difficult to predict the power consumption of Java programs. This unpredictability highlights the need for a specialized tool to accurately measure and analyze power consumption so that developers can optimize their applications for energy efficiency.
Java is an excellent choice for developing this tool because of its high interoperability with various operating systems and its widespread usage across the globe, making it a reliable and option. It has a wide range of useful libraries (JRAPL, JoularJx, Jalen) that help to measure energy accurately, and Java's typing and object-oriented features make the code easier to maintain and extend, so the tool can evolve with new energy metering standards and technologies. 

There are several Java parsing tools available, such as WALA~\cite{wala_main}, SootUp~\cite{sootup_main}, Spoon~\cite{spoon_main} and JavaParser~\cite{javaParser}. WALA and SootUp are primarily designed for analyzing Java Bytecode and are generally more complex to use. For this project, Spoon was chosen because it is a user-friendly tool that facilitates easy retrieval and manipulation of the AST from Java source code. Both JavaParser and Spoon support AST manipulation and code generation. However, Spoon provides a deeper, type-aware metamodel and built-in templating features. These features make Spoon more suitable for generating code that conforms to Java’s syntactic and semantic rules, especially in complex transformation scenarios.


\begin{figure}[htbp]
  \centering
  \includegraphics[scale=0.7]{figures/main_modules.pdf}
  \caption{Main modules}
  \label{fig:main_modules}
\end{figure}




In order to build the extension, it was necessary to build a system architecture capable of providing as final output the functioning tool. The architecture follows different stages, that were deeply analyzed before moving to the next one.
The architecture is divided in 4 main modules~\ref{fig:main_modules}, the Program Generator, Orchestrator, Parser and Tool.



To perform this experiment two computers were used:

\begin{table}[htbp]
\centering
\caption{System Hardware Specifications}
\begin{tabular}{|l|p{10cm}|}
\hline
\textbf{Component} & \textbf{Specification} \\
\hline
\multicolumn{2}{|l|}{\textbf{System 1 — Data Generation and Collection (High-Performance Workstation)}} \\
\hline
Operating System & Ubuntu 24.04.2 LTS (x86\_64) \\
\hline
CPU & AMD Ryzen Threadripper 3960X \\
     & 24 cores / 48 threads \\
     & Base frequency: 2.2 GHz, Boost up to ~5.05 GHz \\
\hline
Memory (RAM) & 94 GiB \\
\hline
GPU & NVIDIA GeForce RTX 3090 Ti (GA102) \\
    & VRAM: 24 GiB (standard) \\
\hline

\multicolumn{2}{|l|}{\textbf{System 2 — Personal Machine for Testing (Lower-Spec)}} \\
\hline
Operating System & Ubuntu 24.04.2 LTS (x86\_64) \\
\hline
CPU & AMD Ryzen 5 3600 \\
     & 6 cores / 12 threads \\
     & Base frequency: 3.6 GHz, Boost up to ~4.2 GHz \\
\hline
Memory (RAM) & 16 GiB \\
\hline
GPU & NVIDIA GeForce RTX 3060 Ti \\
    & VRAM: 8 GiB (standard) \\
\hline
\end{tabular}
\label{tab:hardware_specs}
\end{table}

The more powerful system was used for program generation and data collection, as it was configured to work with SLURM (Simple Linux Utility for Resource Management). SLURM is a highly scalable, open-source job scheduler used to efficiently manage compute resources on shared systems. It allows tasks to be queued and scheduled based on resource availability and job priority, helping to organize workloads across users without manual intervention.

\input{./tex/program_generator}

\input{./tex/orchestrator}

\input{./tex/model_training}

\input{./tex/extension_build}



%\section{Step 3: Implementation and testing} \label{sec:work_step3_implementation_and_testing}
%
%Once the main components of the tool are built, they need to be assembled into the extension. When using it, the developers should be able to see the total energy estimate of their code in the IDE, and it should also show the estimates for each function and its most energy consuming lines.
%The estimate alone may be enough to understand if the code is high or low in energy consumption, for example, if the developer has two implementations of the same function and they both give different values, it may be easy to understand which one consumes the most. However, this may not always be the case, so the tool will also provide some information to help the developer know how good or bad the energy efficiency of the code is.
%
%Another important step is to test and ensure that the tool performs as expected on most machines, delivers the most accurate estimations possible, and undergoes a final comparison with other tools to evaluate its effectiveness.
%